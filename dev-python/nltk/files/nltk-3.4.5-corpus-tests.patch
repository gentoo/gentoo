diff --git a/nltk/test/corpus.doctest b/nltk/test/corpus.doctest
index 5509fe2fd..0a34c9522 100644
--- a/nltk/test/corpus.doctest
+++ b/nltk/test/corpus.doctest
@@ -94,7 +94,7 @@ If the reader methods are called without any arguments, they will
 typically load all documents in the corpus.
 
     >>> len(inaugural.words())
-    145735
+    149797
 
 If a corpus contains a README file, it can be accessed with a ``readme()`` method:
 
@@ -387,8 +387,8 @@ examples illustrate the use of the wordlist corpora:
 
     >>> stopwords.fileids() # doctest: +ELLIPSIS
     ['arabic', 'azerbaijani', 'danish', 'dutch', 'english', 'finnish', 'french', ...]
-    >>> stopwords.words('portuguese') # doctest: +ELLIPSIS
-    ['de', 'a', 'o', 'que', 'e', 'do', 'da', 'em', 'um', 'para', ...]
+    >>> sorted(stopwords.words('portuguese')) # doctest: +ELLIPSIS
+    ['a', 'ao', 'aos', 'aquela', 'aquelas', 'aquele', 'aqueles', ...]
     >>> names.fileids()
     ['female.txt', 'male.txt']
     >>> names.words('male.txt') # doctest: +ELLIPSIS
diff --git a/nltk/test/unit/test_wordnet.py b/nltk/test/unit/test_wordnet.py
index a7b26ac91..a1df3d396 100644
--- a/nltk/test/unit/test_wordnet.py
+++ b/nltk/test/unit/test_wordnet.py
@@ -204,7 +204,7 @@ class WordnNetDemo(unittest.TestCase):
             u'preobrat',
             u'preobrat_v_mi≈°ljenju'
             ]
-        self.assertEqual(S('about-face.n.02').lemma_names(lang='slv'), expected)
+        self.assertEqual(sorted(S('about-face.n.02').lemma_names(lang='slv')), sorted(expected))
 
     def test_iterable_type_for_all_lemma_names(self):
         # Duck-test for iterables.
