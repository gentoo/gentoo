Fix hip compilation with gcc-14
Upstream commit: https://github.com/pytorch/pytorch/commit/8c2c3a03fb87c3568a22362d83b00d82b9fb3db2
--- a/aten/src/ATen/native/cuda/IndexKernel.cu
+++ b/aten/src/ATen/native/cuda/IndexKernel.cu
@@ -259,7 +259,13 @@ void index_put_kernel_quantized_cuda(TensorIterator& iter, const IntArrayRef ind
 
     gpu_index_kernel(iter, index_size, index_stride, [inv_scale, zero_point, qmin, qmax]C10_DEVICE(char* const out_data, const char* const in_data, const int64_t offset) {
       int64_t qvalue = static_cast<int64_t>(zero_point + nearbyintf(*(float*)in_data * inv_scale));
+      // See https://github.com/pytorch/pytorch/issues/127666
+      // hip-clang std::clamp __glibcxx_assert_fail host function when building on Fedora40/gcc14
+#ifndef USE_ROCM
       qvalue = std::clamp(qvalue, qmin, qmax);
+#else
+      qvalue = (qvalue < qmin) ? qmin : (qmax < qvalue) ? qmax : qvalue;
+#endif
       *(scalar_t*)(out_data + offset) = static_cast<scalar_t>(qvalue);
     });
   });
